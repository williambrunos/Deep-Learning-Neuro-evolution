{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williambrunos/Deep-Learning-Neuro-evolution/blob/main/Fundamentals/evolving_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGLnYUqM3NJn"
      },
      "source": [
        "# Evolving Neural Networks\n",
        "\n",
        "## Abstract\n",
        "\n",
        "Evlutionary algorithms are way used to perform topologies, weights, biases and neurons evolutions across neural networks. Sometimes, it's way more pragmatic than other ML algorithms and have to be set to some specific problem.\n",
        "\n",
        "## Algorithm\n",
        "\n",
        "Evolutionary algorithms are based on the premisse of **natural selection**, based on the following steps:\n",
        "\n",
        "- The algorithm starts a population with a certain number of individuals/genomes, with their genotypes or carachteristics being initiated randomly.\n",
        "- The organisms are evaluated based on a **fitness function** or **fitness score**.\n",
        "- The best individuals prom the population are choiced to be parents, performing **asexual reprodution** if the offspring has the same genotype as the parents, or **sexual reprodution** if the offspring has the genotype being a combination of the genotypes of the parents.\n",
        "- Mutate the offspring.\n",
        "- Take back to step two and iterates over these steps until some condition is met, being a maximun number of steps, a threshold of the fitness score etc.\n",
        "\n",
        "## Step 1: The Algorithm\n",
        "\n",
        "We'll be using dense (fully-connected) feed-foward neural networks, like in figure 1:\n",
        "\n",
        "![NN image](https://miro.medium.com/max/700/1*Thii4-1bSrJ1yXwDyW3sjw.png\n",
        ")\n",
        "\n",
        "<center>Dense NN with dimensions [1, 12, 12, 12, 1]</center>\n",
        "\n",
        "In designing our organisms, we have four guiding principles:\n",
        "\n",
        "- We must have control over the input and output dimensions of the organisms. Fundamentally, we are trying to evolve some function f that maps ℝᵃ ⟶ ℝᵇ, so a and b should be built into the organism. We accomplish this by parameterizing the input and output dimensions.\n",
        "- We must have control over the output activation function. The output of the organisms should be appropriate for the problem at hand. We accomplish this by parameterizing the output activation.\n",
        "- We must have control over the complexity of the organisms. The ideal organism should be just complex enough to evolve the target function and no more. We accomplish this by parameterizing the number of hidden layers and their dimensions. In a more advanced algorithm, this could be achieved by letting the organism evolve its own architecture and penalizing complexity with the fitness function.\n",
        "- Organisms must be compatible for sexual reproduction. Fortunately, the above principles ensure that this will be the case. All organisms will have the same architecture, so “exchanging genetic material” here means offspring will get some layer weights from momma and some from poppa.\n",
        "\n",
        "Here's the implementation of an organism:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy"
      ],
      "metadata": {
        "id": "DzHmueES6pSM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Organism():\n",
        "  def __init__(self, dimensions: list, use_bias=True, output='softmax'):\n",
        "    \"\"\"\n",
        "    This function sets up the neural network, using ReLU as the\n",
        "    activation function for all the hidden layers.\n",
        "\n",
        "    params:\n",
        "    -------\n",
        "    dimensions: list -> list of dimensions of the neural network, being the first\n",
        "    one the dimension of the input and the last one the one from output. All the\n",
        "    other ones are dimensions of the hidden leayers.\n",
        "    use_bias: bool -> boolean argument indicating if the neurons are going to\n",
        "    have a bias number\n",
        "    output: string -> used to identify the activation function of output\n",
        "    \"\"\"\n",
        "    # layers sets up a matrix of weights for the dimensions\n",
        "    self.layers = []\n",
        "    # a column os biases for each layer of the NN\n",
        "    self.biases = []\n",
        "    # parameter to decide whether to use bias or not\n",
        "    self.use_bias = use_bias\n",
        "    # output is a ativation function\n",
        "    self.output = self._activation(output)\n",
        "    # Iterates over the N-1 dimensions of the layer to create N-1 weight matrices\n",
        "    # using Glorot Normal Initialization, stored in 'layers'\n",
        "    for i in range(len(dimensions)-1):\n",
        "        shape = (dimensions[i], dimensions[i+1])\n",
        "        std = np.sqrt(2 / sum(shape))\n",
        "        layer = np.random.normal(0, std, shape)\n",
        "        bias = np.random.normal(0, std, (1,  dimensions[i+1])) * use_bias\n",
        "        self.layers.append(layer)\n",
        "        self.biases.append(bias)\n",
        "\n",
        "  def _activation(self, output: str):\n",
        "    \"\"\"\n",
        "    This funcion must return a new activation function to the\n",
        "    output layer of the neural network.\n",
        "\n",
        "    OBS: This output activation function is for the one last layer of the neural\n",
        "    network. All the internal layers have the ReLU function as activation function.\n",
        "\n",
        "    params:\n",
        "    -------\n",
        "    output: str -> this must be a string with the name of the\n",
        "    activation function\n",
        "\n",
        "    returns:\n",
        "    --------\n",
        "    lambda function: function -> represents the activation function by itself\n",
        "    \"\"\"\n",
        "    if output == 'softmax':\n",
        "        return lambda X : np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1, 1)\n",
        "    if output == 'sigmoid':\n",
        "        return lambda X : (1 / (1 + np.exp(-X)))\n",
        "    if output == 'linear':\n",
        "        return lambda X : X\n",
        "  \n",
        "  def predict_choice(self, X, deterministic=True):\n",
        "    probabilities = self.predict(X)\n",
        "    if deterministic:\n",
        "      return np.argmax(probabilities, axis=1).reshape((-1, 1))\n",
        "    if any(np.sum(probabilities, axis=1) != 1):\n",
        "      raise ValueError(f'Output values must sum to 1 to use deterministic=False')\n",
        "    if any(probabilities < 0):\n",
        "      raise ValueError(f'Output values cannot be negative to use deterministic=False')\n",
        "    choices = np.zeros(X.shape[0])\n",
        "    for i in range(X.shape[0]):\n",
        "      U = np.random.rand(X.shape[0])\n",
        "      c = 0\n",
        "      while U > probabilities[i, c]:\n",
        "        U -= probabilities[i, c]\n",
        "        c += 1\n",
        "      else:\n",
        "        choices[i] = c\n",
        "    return choices.reshape((-1,1))\n",
        "\n",
        "  def mutate(self, stdev=0.03):\n",
        "    \"\"\"\n",
        "    This function adds gaussian noise to each weight in all layers of the\n",
        "    neural network.\n",
        "\n",
        "    params:\n",
        "    -------\n",
        "    stdev: float -> standard deviation used to produce the gaussian distribution\n",
        "    noise for the weights.\n",
        "    \"\"\"\n",
        "    for i in range(len(self.layers)):\n",
        "      self.layers[i] += np.random.normal(0, stdev, self.layers[i].shape)\n",
        "      if self.use_bias:\n",
        "        self.biases[i] += np.random.normal(0, stdev, self.biases[i].shape)\n",
        "\n",
        "  def mate(self, other, mutate=True):\n",
        "    # Mate function confirms that both parents are compatible with each other!\n",
        "    if self.use_bias != other.use_bias:\n",
        "      raise ValueError('Both parents must use bias or not use bias')\n",
        "    if not len(self.layers) == len(other.layers):\n",
        "      raise ValueError('Both parents must have same number of layers')\n",
        "    if not all(self.layers[x].shape == other.layers[x].shape for x in range(len(self.layers))):\n",
        "      raise ValueError('Both parents must have same shape')\n",
        "\n",
        "    child = copy.deepcopy(self)\n",
        "    for i in range(len(child.layers)):\n",
        "      pass_on = np.random.rand(1, child.layers[i].shape[1]) < 0.5\n",
        "      child.layers[i] = pass_on * self.layers[i] + ~pass_on * other.layers[i]\n",
        "      child.biases[i] = pass_on * self.biases[i] + ~pass_on * other.biases[i]\n",
        "    if mutate:\n",
        "      child.mutate()\n",
        "    return child\n",
        "\n",
        "  def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    The predict method repeatedly applies ReLU and matrix multiplication \n",
        "    to the input matrix.\n",
        "\n",
        "    params:\n",
        "    -------\n",
        "    X: matrix input\n",
        "    \"\"\"\n",
        "    if not X.ndim == 2:\n",
        "        raise ValueError(f'Input has {X.ndim} dimensions, expected 2')\n",
        "    if not X.shape[1] == self.layers[0].shape[0]:\n",
        "        raise ValueError(f'Input has {X.shape[1]} features, expected {self.layers[0].shape[0]}')\n",
        "    for index, (layer, bias) in enumerate(zip(self.layers, self.biases)):\n",
        "      # Note that the bias here will be spread among a matrix just multiplying the\n",
        "      # random value generated by a matrix of 1's\n",
        "      X = X @ layer + np.ones((X.shape[0], 1)) @ bias\n",
        "      if index == len(self.layers) - 1:\n",
        "        X = self.output(X) # output activation\n",
        "      else:\n",
        "        X = np.clip(X, 0, np.inf)  # ReLU\n",
        "    return X"
      ],
      "metadata": {
        "id": "1QwEyrAr6S4v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Organism Fitness\n",
        "\n",
        "For the time being, it suffices to understand that we require a function scoring_function which accepts an organism as input and returns a real number output, where bigger is better.\n",
        "\n",
        "## Step 3: Reproduction\n",
        "\n",
        "The algorith must select $k$ parents at each iteration: if it this a assexual reproduction, then $k=1$, or $k >= 2$ otherwise. The offspring is set to has $n$ organisms, so the algorithm needs to take $n$ sets of $k$ organisms to compose the parents from the previous generation, considering here a sexual reproduction (and for the following activities).\n",
        "\n",
        "Deciding wich organisms are going to be chosen to compose the set of parents is the initial step of the fitness score, because all the decisions are based on the fitness score of the individuals. Sometimes, depending of the algorithm, it can take a larger amount of genes from the organisms with highest fitness score to compose the genotype of the prole than the ones with lowest scores, but this depends of the implementation of the algorithm. There are some ways to do that:\n",
        "\n",
        "1. Select each parent uniformly from the top 10% of organisms.\n",
        "2. Order the organisms from best to worst, then select the index of each parent by sampling from the exponential distribution.\n",
        "3. Apply the softmax function to each organism’s score to create a probability of selection for each organism, then sample from that distribution.\n",
        "\n",
        "I chose a compromise between methods one and two, where the top 10% of organisms were selected as the first parent of a child ten times each and the second parent was chosen randomly using the exponential distribution, as above. I also enforced that a clone of the best-performing organism of a given generation be included in the next generation, to avoid losing the fitness score in case of making the prole worst than the previous generation. \n",
        "\n",
        "Once n pairs of parents have been chosen, the progeny can be created by randomly combining traits from each pair. In our case, those traits are weights in the neural network layers. Here is the Organism class’s method for progeny creation.\n",
        "\n",
        "## Step 4: Mutation\n",
        "\n",
        "After a child is produced, it is subjected to mutation, the mutation step is realized as the addition of Gaussian noise to each weight in the network. We do not change the activations or architecture of the network here, although a more advanced evolutionary algorithm could certainly do so by adding or removing nodes in the hidden layers\n",
        "\n",
        "## Stpe 5: Repeat\n",
        "\n",
        "This is hardly a step; all that remains to be done is check if some condition is met, and to return to step two if it has not. I chose to run the algorithm for a fixed number of generations, but stopping when the fitness score hits a desired threshold or after some number of generations pass without improvement are also good choices\n",
        "\n",
        "Here's some relevant code:"
      ],
      "metadata": {
        "id": "jlBC8OD594xH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Ecosystem():\n",
        "  def __init__(self, original_f, scoring_function, population_size=100, holdout='sqrt', mating=True):\n",
        "    \"\"\"\n",
        "    Sets up the ecossystem object.\n",
        "\n",
        "    params:\n",
        "    -------\n",
        "    - original_f: lambda -> must be a function to produce Organisms, used for the original population.\n",
        "    - scoring_function: lambda -> must be a function which accepts an Organism as input and returns a float.\n",
        "    - population_size: int -> population size over the generations. Default: 100.\n",
        "    - holdout: str -> Sets the strategy of accounting of number of organisms that \n",
        "    are guaranteed progeny. Default: 'sqrt'.\n",
        "    - mating: Boolean -> This argument sets the sexual mating, implying that two parents are going to be\n",
        "    select to spread their genes. Default: True\n",
        "    \"\"\"\n",
        "\n",
        "    self.population_size = population_size=100\n",
        "    self.population = [original_f() for _ in range(population_size)]\n",
        "    self.scoring_function = scoring_function\n",
        "    if holdout == 'sqrt':\n",
        "      self.holdout = max(1, int(np.sqrt(population_size)))\n",
        "    elif holdout == 'log':\n",
        "      self.holdout = max(1, int(np.log(population_size)))\n",
        "    elif holdout > 0 and holdout < 1:\n",
        "      self.holdout = max(1, int(holdout * population_size))\n",
        "    else:\n",
        "      self.holdout = max(1, int(holdout))\n",
        "    self.mating = mating\n",
        "\n",
        "  def generation(self, repeats=1, keep_best=True):\n",
        "    # For each organism x in the population, this function will apply the scoring\n",
        "    # function {repeats} times until numpy gets the mean of these scores \n",
        "    # Scores the organisms and sorts it in ascending order\n",
        "    rewards = [np.mean([self.scoring_function(x) for _ in range(repeats)]) for x in self.population]\n",
        "    # Sorts the population based on the rewards array, starting with the highest ones\n",
        "    self.population = [self.population[index] for index in np.argsort(rewards)[::-1]]\n",
        "\n",
        "    # New population after the natural selection\n",
        "    new_population = []\n",
        "    for i in range(self.population_size):\n",
        "      # Selects a part of the population to have their genes guaranteed in the offspring\n",
        "      parent_1_idx = i % self.holdout\n",
        "      if self.mating:\n",
        "        # Selects the second parent based on the exponential distribution\n",
        "        parent_2_idx = min(self.population_size - 1, int(np.random.exponential(self.holdout)))\n",
        "      else:\n",
        "        # If mating = False, then the reproduction is asexual\n",
        "        parent_2_idx = parent_1_idx\n",
        "      offspring = self.population[parent_1_idx].mate(self.population[parent_2_idx])\n",
        "      new_population.append(offspring)\n",
        "\n",
        "    if keep_best:\n",
        "      # Ensure best organism survives\n",
        "      new_population[-1] = self.population[0] \n",
        "    self.population = new_population\n",
        "\n",
        "  def get_best_organism(self, repeats=1, include_reward=False):\n",
        "    # Scores the organisms and sorts it in ascending order\n",
        "    rewards = [np.mean(self.scoring_function(x)) for _ in range(repeats) for x in self.population]\n",
        "    if include_reward:\n",
        "      best = np.argsort(rewards)[-1]\n",
        "      return self.population[best], rewards[best]\n",
        "    else:\n",
        "      return self.population[np.argsort(rewards)[-1]]"
      ],
      "metadata": {
        "id": "ZIj4JjOhAnHg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applications\n",
        "\n",
        "### Regression\n",
        "\n",
        "Let's apply the algorithm to a regression problem. We will set the parameters of the neural network and evolve the organisms that represents the weights of the network that tries to fit data into a $sin(\\tau X)$ function, being $\\tau = 2\\pi$. The biggest challenge in the implementations is: how to design the organisms?\n",
        "\n",
        "1. This function is from $\\mathbb{R}^1 \\Rightarrow \\mathbb{R}^1$, so both the input and output dimension will be 1.\n",
        "2. The range of sine is [-1, 1], so the output activation will be linear (X -> X). \n",
        "3. The fitness function will be the negative mean suqared error of the organism output (This one has to be maximized).\n",
        "4. We'll use three hidden layers, each one with width 16."
      ],
      "metadata": {
        "id": "ls4-G2HzAadd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The function to create the initial population\n",
        "organism_creator = lambda : Organism([1, 16, 16, 16, 1], output='linear')\n",
        "# The function we are trying to learn. numpy doesn't have tau...\n",
        "true_function = lambda x : np.sin(2 * np.pi * x) \n",
        "# The loss function, mean squared error, will serve as the negative fitness\n",
        "loss_function = lambda y_true, y_estimate : np.mean((y_true - y_estimate)**2)\n",
        "\n",
        "def simulate_and_evaluate(organism, replicates=1):\n",
        "    \"\"\"\n",
        "    Randomly generate {replicates} samples in [0,1],\n",
        "    use the organism to predict their corresponding value,\n",
        "    and return the fitness score of the organism\n",
        "    \"\"\"\n",
        "    X = np.random.random((replicates, 1))\n",
        "    predictions = organism.predict(X)\n",
        "    loss = loss_function(true_function(X), predictions)\n",
        "    return -loss\n",
        "\n",
        "# Ecosystem requires a function that maps an organism to a real number fitness\n",
        "scoring_function = lambda organism : simulate_and_evaluate(organism, replicates=100)\n",
        "# Create the ecosystem - note that population_size and replicates must be equal\n",
        "ecosystem = Ecosystem(organism_creator, scoring_function, \n",
        "                      population_size=100, holdout=0.1, mating=True)\n",
        "# Save the fitness score of the best organism in each generation\n",
        "best_organism_scores = [ecosystem.get_best_organism(include_reward=True)[1]]\n",
        "generations = 201\n",
        "for i in range(generations):\n",
        "    ecosystem.generation()\n",
        "    this_generation_best = ecosystem.get_best_organism(include_reward=True)\n",
        "    this_generation_best_layers = this_generation_best[0].layers\n",
        "    best_organism_scores.append(this_generation_best[1])\n",
        "print(best_organism_scores)\n",
        "print(this_generation_best_layers)"
      ],
      "metadata": {
        "id": "sl7oruED1PUw",
        "outputId": "c5ff9dc5-d293-43b5-f1cb-077d6b4d13b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.35966404093931736, -0.38334430939934394, -0.378026183370214, -0.29723180694315704, -0.2929712938089437, -0.28867165143989215, -0.2533375808708792, -0.25022511446544216, -0.2231742612454947, -0.20984567990493844, -0.1857413519700642, -0.17838783236696798, -0.1530286770100774, -0.14652076889756174, -0.15893832877395245, -0.1536690122989059, -0.1417801655459078, -0.14781936236384233, -0.13615555129806606, -0.1219811022194195, -0.12600475544252013, -0.12964472295566565, -0.13021504151033164, -0.10380475478154715, -0.12360448191959097, -0.13838487019455015, -0.1415226466910073, -0.13026129435199615, -0.1305670195984531, -0.11586475692973208, -0.12074243356868598, -0.1275912996928011, -0.11568322421805056, -0.12397048830859778, -0.09431392430978333, -0.09994635285142228, -0.10408467830579447, -0.0987197996796262, -0.1069230945300952, -0.08626397200544664, -0.09143144513631243, -0.09201649018640873, -0.10908252758303835, -0.10753265339980768, -0.09417413785253358, -0.0936796712451706, -0.07201982606139279, -0.07161839088591455, -0.07654086120172926, -0.08186427178542113, -0.07728762079195647, -0.08274568422103018, -0.08281751091857922, -0.08720763209253914, -0.0776699154396235, -0.08656938987355942, -0.07499589262039477, -0.07643695175738374, -0.06866932018903366, -0.06322684522394045, -0.07219251023055911, -0.052629059745159655, -0.06158293149680997, -0.05955986344421344, -0.04894920704497439, -0.06368943821912167, -0.0528936540017568, -0.045198035162532714, -0.05446990814752334, -0.04775556066173267, -0.04748093460189136, -0.03384188934852653, -0.03732263974706446, -0.033456815497039896, -0.03239832159541533, -0.03543218840339559, -0.03532182767255959, -0.03279091152212414, -0.034482108831777845, -0.02605449371854565, -0.030900667022269658, -0.027344985807711834, -0.021465742313356632, -0.02207797946143212, -0.026069304227553335, -0.027440674888795296, -0.023121270002935273, -0.02521344991588868, -0.02895679170854114, -0.02517161829931629, -0.024718172435730865, -0.03125857288696853, -0.024412402701589907, -0.014631222490580138, -0.015258281138560443, -0.014128248951960774, -0.019506477156920096, -0.018319643734274752, -0.018661801828261132, -0.02108428146071027, -0.01998052406337903, -0.023454746332938106, -0.018510613106736747, -0.021566866726485254, -0.015542154724424235, -0.014090539288693114, -0.009715223605198962, -0.016782882453438404, -0.011512837245159183, -0.016172251310172286, -0.012164657602293415, -0.011946003398217586, -0.013998532984492123, -0.012397983990963566, -0.018039785708792336, -0.00922161673076953, -0.009743450392564284, -0.009346143325382753, -0.01382462052522509, -0.010573488652333728, -0.011210494760509296, -0.011394252500476282, -0.013137247669575058, -0.01363083622814469, -0.013150636203820227, -0.01401717759874357, -0.009293392485831024, -0.006925027372012139, -0.006649508874893342, -0.007995644653744796, -0.007837179888080009, -0.006988572051628196, -0.007485490467585689, -0.008493226774300634, -0.007124177495562775, -0.009111335020182415, -0.0072519140591018605, -0.007986254322278327, -0.007960893365674952, -0.005905213963731103, -0.009180721473520703, -0.005051847253881948, -0.004019717434619462, -0.004841325918730764, -0.005160186218257606, -0.006915645588341913, -0.007850468873671497, -0.008692838482363616, -0.006127555209197328, -0.007469509054874217, -0.006682880621302189, -0.006417719755931952, -0.007964087767368516, -0.00872013960332957, -0.007132649837796096, -0.008702936846649715, -0.006330865656362201, -0.00606362243866563, -0.006905877084401129, -0.008027296127813732, -0.007078325188478956, -0.006856452488587778, -0.007372822657156514, -0.008677690022016077, -0.007443269975837751, -0.0085131859620164, -0.006401055882604892, -0.009308124868033993, -0.006511261493349987, -0.004404061807973551, -0.005018494514350125, -0.005469869919652835, -0.004610679952523834, -0.0052328189636238346, -0.004842831600420238, -0.004079524683592418, -0.004474281007466074, -0.005137187129710623, -0.00432933009550759, -0.004096311398574103, -0.004035065184768188, -0.005519498086071528, -0.005706502947045769, -0.004852886551631385, -0.004874415261070229, -0.004357363426108335, -0.006133035188166207, -0.0066201431520046625, -0.005488688319832119, -0.007917979787085692, -0.007841165504453029, -0.006808380551929318, -0.006929099266018205, -0.005463756261739663, -0.007744681032876958, -0.007363693921294605, -0.008648221891368104, -0.008359542079420497, -0.006260906468082601, -0.0070092435070142215, -0.008001501026048831, -0.006429022019504718]\n",
            "[array([[ 0.56065979,  0.03571093,  0.67001446, -0.38322906,  0.66719315,\n",
            "        -0.20914342,  0.15090736,  0.91410525,  1.3002558 ,  0.09307537,\n",
            "         1.16737768, -0.28613552, -0.36795288,  0.35766081,  0.92215254,\n",
            "         0.58803786]]), array([[ 0.31330143,  0.09497052,  0.27261527,  0.12705598, -0.28746073,\n",
            "        -0.01615765, -0.57982657,  0.50736044, -0.05297635,  0.17743327,\n",
            "         0.28275232,  0.11782954, -0.22474807, -1.03473702, -0.10962551,\n",
            "         0.39040009],\n",
            "       [-0.23027134,  0.32095945, -0.04694243, -0.10787477,  0.21300465,\n",
            "        -0.19116912,  0.05386953,  0.4125393 , -0.51980791,  0.25826037,\n",
            "        -0.46708582,  0.03983363,  0.02671561,  0.29680679,  0.15907036,\n",
            "         0.25275298],\n",
            "       [-0.33061669, -0.01351189, -0.31345582, -0.33783829,  0.01561816,\n",
            "         1.06547837,  0.54579043, -0.30316898,  0.13639861,  0.08562188,\n",
            "        -0.30198869, -0.49124947, -0.5535095 , -0.37684214, -0.12384025,\n",
            "        -0.54397079],\n",
            "       [ 0.15256298,  0.49439365,  0.39788784,  0.14752647, -0.07779752,\n",
            "        -0.66344782, -0.09060479, -0.26129831,  0.43916823,  0.02289772,\n",
            "        -0.23521478, -0.50579308,  0.18243218, -0.30857819, -0.5439848 ,\n",
            "        -0.63214203],\n",
            "       [ 0.49025926,  1.22174611,  0.58618713, -0.05383251, -0.6479701 ,\n",
            "         1.23834607,  1.31191334,  0.43095173, -0.61653427, -0.17377899,\n",
            "        -0.73351852,  0.74527092, -0.48543872,  0.80110568,  0.19506005,\n",
            "         0.01252548],\n",
            "       [-0.17306409, -0.61674643, -0.08943779,  0.48945444, -0.54848282,\n",
            "        -0.6027893 , -0.09433548,  1.07882538, -0.43769549, -0.17988224,\n",
            "        -0.67569447,  0.11609443,  0.56129793, -0.14826359, -0.2246545 ,\n",
            "        -0.73619402],\n",
            "       [ 0.68219814,  0.09178355,  0.96163552, -0.55679964, -0.33751779,\n",
            "         0.14374477,  0.43707391, -0.08543892, -0.2056464 , -0.14542489,\n",
            "         0.21750404, -0.16119406, -0.33916264, -0.2580314 , -0.82946219,\n",
            "        -0.58819617],\n",
            "       [-0.05942176, -0.80115138, -0.43379292,  0.29983706, -0.41506561,\n",
            "        -0.24610533,  0.47355956,  0.30619204,  0.80229416, -0.19495069,\n",
            "        -0.39649652, -0.77994319,  0.59010958,  0.06388812,  0.24364592,\n",
            "         0.1862454 ],\n",
            "       [-0.31744   ,  0.01979829, -0.90580257,  0.42275182, -0.23766864,\n",
            "         0.68507596,  0.41922735,  0.31354038,  0.34279473,  0.0607969 ,\n",
            "         0.42690066,  0.72886045, -0.46890549,  0.0518811 ,  0.79889501,\n",
            "         0.35270355],\n",
            "       [ 0.10337375, -0.13034644,  0.40039969,  0.3320434 ,  0.01183968,\n",
            "        -0.20840656, -0.13909477,  0.47801549, -0.32874638, -0.05798635,\n",
            "        -0.03232886, -0.22243356,  0.1280076 ,  0.17715541, -0.3717362 ,\n",
            "         0.03125545],\n",
            "       [-0.12010996, -0.51375166, -0.06886414,  0.3282348 , -0.67966629,\n",
            "         0.84879181, -0.59725885,  0.48703414,  0.23801353, -0.31646699,\n",
            "         0.08761699,  0.20850872,  0.20021126,  0.62813132,  0.02540943,\n",
            "        -0.41472926],\n",
            "       [ 0.12153168, -0.14446868,  0.29788856, -0.06579982, -0.18929625,\n",
            "         0.55382128, -0.44883763,  0.1054333 ,  0.15676763, -0.01973291,\n",
            "        -0.29332417,  0.39984368,  0.04344751,  0.39643362,  0.42025125,\n",
            "        -0.73842013],\n",
            "       [ 0.42760474,  0.43592086, -0.23846627, -0.26147077, -0.04885596,\n",
            "         0.65284318,  0.42909318, -0.56914719,  0.66302896, -0.68051871,\n",
            "         0.21565648,  0.13851924,  0.26932854, -0.44855231, -0.66135868,\n",
            "         0.06390561],\n",
            "       [-0.50423115,  0.31175279, -0.69969981, -0.50674139, -0.1546025 ,\n",
            "        -0.26951876,  0.0099321 ,  0.41736875,  0.48050962, -0.70238523,\n",
            "         0.01632175,  0.06760312,  0.01862825,  0.17153744,  0.39946149,\n",
            "        -0.68599866],\n",
            "       [-0.29893511,  0.22971755, -0.18208008, -0.75264446, -1.00773492,\n",
            "         0.06447014, -0.46536572,  0.01078725, -0.47950017,  0.8250557 ,\n",
            "         0.21611595, -0.20244056, -0.64709752,  0.36369408,  0.26395488,\n",
            "         0.12831403],\n",
            "       [ 0.36172664,  0.2334    ,  0.16316882,  0.37427205, -0.4243837 ,\n",
            "        -0.64610227,  0.08744295,  0.90799739, -0.55234877,  0.29077534,\n",
            "         0.16362044,  0.06471955,  0.70022842, -0.51483715,  0.79227248,\n",
            "         0.45587965]]), array([[-0.27603482,  0.01491282,  0.16166576,  0.00362907,  0.2741714 ,\n",
            "        -0.57156678,  0.68320694,  0.29464476, -0.91162981,  0.57511074,\n",
            "         0.27850832, -0.32542029,  0.39144838, -0.16929105, -0.27006735,\n",
            "         0.44577561],\n",
            "       [-0.37106889, -0.01364314, -1.19551753, -0.6011455 , -0.36730844,\n",
            "        -0.2050231 , -0.05139656,  0.29245327, -0.25113868, -0.27226515,\n",
            "        -0.39627635,  0.20137873,  0.11534137,  0.24452453,  0.59474257,\n",
            "         0.39303574],\n",
            "       [ 0.75184977, -0.31334557, -0.55630523,  0.71961933, -0.03704405,\n",
            "         0.01924435,  0.65686185, -0.3072754 ,  0.17801001,  0.296827  ,\n",
            "        -0.28618041, -0.42249711, -0.06194459,  0.25777053,  0.04912924,\n",
            "         0.21359217],\n",
            "       [-0.59645778, -0.49051095, -0.10639925,  0.23714384, -0.25927806,\n",
            "         0.21516135, -0.42636955,  0.33013561, -0.41952859,  0.13997993,\n",
            "        -0.32056078, -0.87246553,  0.07716112,  0.52546191, -0.43522251,\n",
            "         1.02293688],\n",
            "       [ 0.52084786, -0.73412134,  0.80847591, -0.58855471, -0.21304329,\n",
            "         0.67263096,  0.36263975, -0.09483692, -0.42795381,  0.19082793,\n",
            "        -0.01691124, -0.79463287,  0.68820775,  0.05107911, -0.54318503,\n",
            "         0.06169771],\n",
            "       [-0.52981436, -0.43520997, -0.50058449, -0.94239338,  0.08592469,\n",
            "         1.17693229,  0.692463  ,  0.02716131,  0.06557224,  0.07184835,\n",
            "        -0.45890086, -0.55118223, -0.54529916, -0.88886682,  0.54992685,\n",
            "        -0.07501715],\n",
            "       [ 0.26800157,  0.26637856,  0.58538369,  0.89872458, -0.42153299,\n",
            "        -0.29286237, -0.71852941,  0.21035771,  0.06074345, -0.16663268,\n",
            "         0.15922447,  1.50138959, -0.18018425, -0.05439751,  0.18175529,\n",
            "         0.87670758],\n",
            "       [ 0.19816694,  0.61830004,  0.00523904,  0.23277054,  0.31301179,\n",
            "         0.08552517, -0.41864235,  0.21108114,  0.36859135,  0.36031422,\n",
            "        -1.06410191, -0.51971546, -0.15697873,  0.02694078, -0.32266541,\n",
            "         1.18119489],\n",
            "       [-0.67670378,  0.42316781,  0.2919846 , -0.18904265,  0.17644866,\n",
            "        -0.19510631, -0.04687561,  0.4554942 , -0.02094918, -0.20353114,\n",
            "        -0.31762065,  0.01837425,  0.44656259, -0.493654  ,  0.27311479,\n",
            "         0.70228818],\n",
            "       [-0.14869725, -0.13673731,  0.67019772,  0.59683945, -0.11566987,\n",
            "         0.1528545 ,  0.63687869, -0.40204961,  0.89159525, -0.01041072,\n",
            "        -0.79219259, -0.70577042, -0.77411124, -0.03249103, -0.24289993,\n",
            "        -1.04622926],\n",
            "       [-0.18997463,  0.71183724, -0.25671073, -0.82570352,  0.13425817,\n",
            "         0.83573332, -0.20204735, -0.01545602,  0.01272257, -0.56269795,\n",
            "        -0.02865092,  0.0072717 , -0.25047075,  0.15030588,  0.23977703,\n",
            "        -0.16808941],\n",
            "       [ 0.30951511,  0.39333569,  0.39846518,  0.6806369 ,  0.04286497,\n",
            "         0.05306542, -0.44840247,  0.07191262,  0.14998023, -0.0856621 ,\n",
            "        -0.89100539,  0.72606884, -0.1360104 , -0.28248588,  0.6850329 ,\n",
            "         0.50790664],\n",
            "       [-0.11700494, -0.37618348,  0.17116428, -0.66262831, -0.55759204,\n",
            "         0.35869867, -0.25425202, -0.43067708, -0.17815001, -0.90735755,\n",
            "        -0.60502733,  0.40459777, -0.47032873, -0.02914041, -0.1138028 ,\n",
            "         0.13322155],\n",
            "       [-0.3405685 , -0.34283388,  0.55460884, -0.35463939,  0.32061893,\n",
            "        -0.21972077,  0.49758076, -0.03059178,  0.74136388, -0.04611406,\n",
            "        -0.06476491, -0.20583931,  0.49321199, -0.27765383, -0.21937132,\n",
            "        -0.16485913],\n",
            "       [-0.69831166, -0.41179454,  0.14425214,  0.27056494,  0.13111128,\n",
            "         0.72853   ,  0.05463927, -0.21703737,  0.49799024, -0.62107877,\n",
            "         0.31654996, -0.1907426 , -0.70643349, -0.04351769,  0.72287224,\n",
            "         0.02124013],\n",
            "       [ 0.05890615, -0.74678003,  0.2232244 , -0.44854335,  0.16181942,\n",
            "        -1.178745  ,  0.28162925, -0.12222671, -0.53065344,  0.84960707,\n",
            "        -0.40101841,  0.31478641,  0.41605277, -0.41577398,  0.63373259,\n",
            "        -0.03860789]]), array([[ 0.01145798],\n",
            "       [-1.23320762],\n",
            "       [-0.80530193],\n",
            "       [ 0.77887265],\n",
            "       [-0.76871269],\n",
            "       [ 1.10053893],\n",
            "       [-0.31694342],\n",
            "       [ 0.19975601],\n",
            "       [-0.03483383],\n",
            "       [ 0.21494711],\n",
            "       [ 0.35324096],\n",
            "       [-0.43533399],\n",
            "       [ 0.3301799 ],\n",
            "       [ 0.72335613],\n",
            "       [-0.46739328],\n",
            "       [ 0.17814513]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "0nwCspA7GkLP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VslkWGtIHC5t",
        "outputId": "e548bc48-cfe5-4402-fa3b-2144d8820d80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
              "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
              "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
              "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
              "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
              "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
              "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
              "       196, 197, 198, 199, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generations_array = np.arange(0, generations + 1, 1)\n",
        "plt.plot(generations_array, best_organism_scores)"
      ],
      "metadata": {
        "id": "RKnktS3wGy1A",
        "outputId": "3883a3c0-9aef-482b-8109-5e19ada43c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f42f54f5a50>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refferences\n",
        "\n",
        "[Mediun article - Evolving Neural Networks](https://towardsdatascience.com/evolving-neural-networks-b24517bb3701)\n",
        "\n",
        "[Paper randomly initiating weights](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
        "\n",
        "[Guia markdown](https://medium.com/walternascimentobarroso-pt/curso-r%C3%A1pido-de-markdown-4af49e3bfa65#:~:text=Para%20centralizar%20itens%20no%20markdown,usar%20a%20tag%20.)\n",
        "\n",
        "[Activation functions article](https://usernamejack.medium.com/analyzing-the-activation-functions-of-common-neural-networks-4dcdaa92a055)"
      ],
      "metadata": {
        "id": "CakEXWZX3t7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z3azAAMC1OkG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "evolving_neural_networks.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}